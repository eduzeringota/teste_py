{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becoming-coalition",
   "metadata": {},
   "source": [
    "# <font color='red'>1.0 IMPORT</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collectible-company",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.367027Z",
     "start_time": "2021-03-16T12:59:39.572607Z"
    }
   },
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "\n",
    "# !pip install mysql-connector-python\n",
    "# !pip install pymysql\n",
    "# !pip install sqlalchemy\n",
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pd.options.display.max_rows = 2000\n",
    "# pd.options.display.width = 120\n",
    "# pd.options.display.max_colwidth = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-collar",
   "metadata": {},
   "source": [
    "# <font color='red'>2.0 EXTRACT</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blocked-hanging",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.376030Z",
     "start_time": "2021-03-16T12:59:40.369392Z"
    }
   },
   "outputs": [],
   "source": [
    "def LeFontes(strAut):\n",
    "    sql_form = (\n",
    "    \"SELECT `atributo`, `valor`, `protocolo` \"\n",
    "    \"FROM form \"\n",
    "    \"WHERE `atributo` IN ('state', 'city', 'neighborhood', 'zipcode', 'street')\"\n",
    "    )\n",
    "    sql_tasks = (\n",
    "    \"SELECT `Protocolo`, `Entidade`, `Serviço`, `Usuário`, `Grupo`, `Data e Hora de conclusão`, \"\n",
    "    \"`Data e Hora de criação`, `Ação`, `Encaminhado para`, `Processo encerrado`, `Processo cancelado`, \"\n",
    "    \"`Motivo de cancelamento`, `Status externo`, `Categoria`, `Grupo responsável`, `Prazo (em segundos)` \"\n",
    "    \"FROM tasks\"\n",
    "    )\n",
    "    sql_sla = (\n",
    "    \"SELECT * \"\n",
    "    \"FROM sla\"\n",
    "    )\n",
    "    sql_rating = (\n",
    "    \"SELECT * \"\n",
    "    \"FROM rating\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        connection = mysql.connector.connect(host     = strAut['My_host'], \n",
    "                                             database = strAut['My_db'], \n",
    "                                             user     = strAut['My_user'], \n",
    "                                             password = strAut['My_pw'])\n",
    "\n",
    "        df_int_tasks =   pd.read_sql(sql_tasks,  con=connection)\n",
    "        df_int_sla =     pd.read_sql(sql_sla,    con=connection)\n",
    "        df_int_form =    pd.read_sql(sql_form,   con=connection)\n",
    "        df_int_rating =  pd.read_sql(sql_rating, con=connection)\n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Failed to read record from MySQL table {}\".format(error))\n",
    "\n",
    "    finally:\n",
    "        if (connection.is_connected()):\n",
    "            connection.close()\n",
    "            print(f'tasks:{df_int_tasks.shape[0]} registros lidos em {df_int_tasks.shape[1]} colunas')\n",
    "            print(f'sla: {df_int_sla.shape[0]} registros lidos em {df_int_sla.shape[1]} colunas')\n",
    "            print(f'form: {df_int_form.shape[0]} registros lidos em {df_int_form.shape[1]} colunas')\n",
    "            print(f'rating: {df_int_rating.shape[0]} registros lidos em {df_int_rating.shape[1]} colunas')\n",
    "            print(\"MySQL connection is closed\")\n",
    "            \n",
    "    return df_int_tasks, df_int_sla, df_int_form, df_int_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-river",
   "metadata": {},
   "source": [
    "# <font color='red'>3.0 TRANSFORM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-providence",
   "metadata": {},
   "source": [
    "# <font color='blue'>trata os datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-night",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset sla</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weekly-martial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.388044Z",
     "start_time": "2021-03-16T12:59:40.379020Z"
    }
   },
   "outputs": [],
   "source": [
    "def trSLA(df):\n",
    "    MINUTOS_PARA_DIAS = 1440 # quantidade de minutos em um dia\n",
    "\n",
    "    # preenche com null as colunas que contém 'null' como tipo string\n",
    "    df.loc[(df['limiteMinimo'] == 'null'), 'limiteMinimo'] = np.nan\n",
    "    df.loc[(df['limiteMaximo'] == 'null'), 'limiteMaximo'] = np.nan\n",
    "\n",
    "    # transforma o tipo de coluna para float\n",
    "    df['limiteMinimo'] = df['limiteMinimo'].astype(float)\n",
    "    df['limiteMaximo'] = df['limiteMaximo'].astype(float)\n",
    "\n",
    "    # transforma a unidade de medida de minuto para dias\n",
    "    df['limiteMinimo'] = df['limiteMinimo'] / MINUTOS_PARA_DIAS\n",
    "    df['limiteMaximo'] = df['limiteMaximo'] / MINUTOS_PARA_DIAS\n",
    "\n",
    "    # preenche com valores extremos os limites máximos e limites mínimos\n",
    "    df.loc[(df['limiteMinimo'].isna()), 'limiteMinimo'] = -9999999.9\n",
    "    df.loc[(df['limiteMaximo'].isna()), 'limiteMaximo'] = 9999999.9\n",
    "\n",
    "    # cria mais uma coluna de status para pivotar limite mínimo e limite máxio\n",
    "    df['status2'] = df['status']\n",
    "    df.rename(columns={'status': 'StatusLmin', 'status2': 'StatusLmax'}, inplace = True)\n",
    "    \n",
    "    # faz pivot da coluna StatusLmin\n",
    "    idx = ['entityCode', 'service', 'StatusLmax', 'limiteMaximo']\n",
    "    df = df.pivot(columns = 'StatusLmin', values = 'limiteMinimo', index=idx).reset_index()\n",
    "    df.columns.name = None\n",
    "    dic_renome = {'Dentro do prazo' : 'Dentro do Prazo LMin', \n",
    "                  'Fora do prazo' : 'Fora do Prazo LMin',\n",
    "                  'Perto do prazo' : 'Perto do Prazo LMin'}\n",
    "    df.rename(columns=dic_renome, inplace = True)\n",
    "\n",
    "    # faz pivot da coluna StatusLmax\n",
    "    idx = ['entityCode', 'service', 'Dentro do Prazo LMin', 'Fora do Prazo LMin', 'Perto do Prazo LMin']\n",
    "    df = df.pivot(columns = 'StatusLmax', values = 'limiteMaximo', index=idx).reset_index()\n",
    "    df.columns.name = None\n",
    "    dic_renome = {'Dentro do prazo' : 'Dentro do Prazo LMax', \n",
    "                  'Fora do prazo' : 'Fora do Prazo LMax',\n",
    "                  'Perto do prazo' : 'Perto do Prazo LMax'}\n",
    "    df.rename(columns=dic_renome, inplace = True)\n",
    "\n",
    "    # agrupa por entidade e serviço\n",
    "    df = df.groupby('service').sum().reset_index()\n",
    "\n",
    "    print('df_sla transformado')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-pierre",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset form</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scheduled-auction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.396743Z",
     "start_time": "2021-03-16T12:59:40.391138Z"
    }
   },
   "outputs": [],
   "source": [
    "def trForm(df):\n",
    "    \n",
    "    # faz pivot da coluna atributo\n",
    "    df = df.pivot(columns='atributo', values='valor', index='protocolo').reset_index()\n",
    "    df.columns.name = None\n",
    "\n",
    "    # renomeia colunas\n",
    "    dic_renome = {'protocolo': 'Solicitacao', \n",
    "                  'zipcode': 'CEP', \n",
    "                  'street': 'Endereco', \n",
    "                  'neighborhood': 'Bairro', \n",
    "                  'city': 'Cidade', \n",
    "                  'state': 'UF'}\n",
    "    df.rename(columns=dic_renome, inplace = True)\n",
    "    \n",
    "    # substitui a coluna Endereco por branco quando '-' ou null\n",
    "    df.loc[(df['Endereco'] == '-') | (df['Endereco'].isnull()), ['Endereco']] = ''\n",
    "    df.loc[(df['Bairro'] == '-') | (df['Bairro'].isnull()), ['Bairro']] = ''\n",
    "\n",
    "    # cria a coluna Endereco Completo\n",
    "    df['EnderecoCompleto'] = df['Cidade'] + ', ' + df['UF'] + ', Brasil'\n",
    "    \n",
    "    print('df_form transformado')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-yukon",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset rating</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dynamic-jason",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.403395Z",
     "start_time": "2021-03-16T12:59:40.399214Z"
    }
   },
   "outputs": [],
   "source": [
    "def trRating(df):\n",
    "\n",
    "    # renomeia as colunas\n",
    "    cols = ['Solicitacao', 'NotaAvaliacao', 'MotivoAvaliacao', 'DataHoraAvaliacao']\n",
    "    df.columns = cols\n",
    "\n",
    "    # separa e formata as colunas de datas e horas \n",
    "    df['DataAvaliacao'] = pd.to_datetime(df['DataHoraAvaliacao']).dt.date\n",
    "    df['HoraAvaliacao'] = pd.to_datetime(df['DataHoraAvaliacao']).dt.time\n",
    "\n",
    "    # deleta a coluna que contém data e hora\n",
    "    df.drop(['DataHoraAvaliacao'], axis=1, inplace=True)\n",
    "\n",
    "    # preenche colunas de linhas vazias\n",
    "    df.loc[df['MotivoAvaliacao'] == '', 'MotivoAvaliacao'] = '<motivo vazio>'\n",
    "    \n",
    "    print('df_rating transformado')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-democrat",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset tasks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assumed-blast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.414186Z",
     "start_time": "2021-03-16T12:59:40.406606Z"
    }
   },
   "outputs": [],
   "source": [
    "def trTasks(df):\n",
    "\n",
    "    SEM_STATUS = '<sem status inicial>'\n",
    "    \n",
    "    # renomeia as colunas\n",
    "    lst_colunas_tasks = ['Protocolo', 'Entidade', 'Servico', 'Usuarios','Grupo', 'DataHora_Conclusao',\n",
    "                          'DataHora_Criacao', 'Acao', 'EncaminhadoPara', 'ProcessoEncerrado', 'ProcessoCancelado',\n",
    "                          'MotivoCancelamento', 'StatusExterno', 'Categoria', 'GrupoResponsavel','Prazo']\n",
    "    df.columns = lst_colunas_tasks\n",
    "\n",
    "    # rotina para preencher status externo vazio\n",
    "    # pega sempre o anterior e se o primeiro status estiver vazio coloca \"sem status inicial\"\n",
    "    if df.loc[0, 'StatusExterno'] == '':\n",
    "        df.loc[0, 'StatusExterno'] = SEM_STATUS\n",
    "    for i in range(1, df.shape[0]):\n",
    "        if df.loc[i, 'StatusExterno'] == '':    \n",
    "            if df.loc[i, 'Protocolo'] == df.loc[i - 1, 'Protocolo']:\n",
    "                df.loc[i, 'StatusExterno'] = df.loc[i - 1, 'StatusExterno']\n",
    "            else:\n",
    "                df.loc[i, 'StatusExterno'] = SEM_STATUS\n",
    "\n",
    "    if df.loc[0, 'StatusExterno'] == '':\n",
    "        df.loc[0, 'StatusExterno'] = '<sem status inicial>'\n",
    "    for i in range(1, df.shape[0]):\n",
    "        if df.loc[i, 'StatusExterno'] == '':    \n",
    "            if df.loc[i, 'Protocolo'] == df.loc[i - 1, 'Protocolo']:\n",
    "                df.loc[i, 'StatusExterno'] = df.loc[i - 1, 'StatusExterno']\n",
    "            else:\n",
    "                df.loc[i, 'StatusExterno'] = '<sem status inicial>'\n",
    "    \n",
    "    print('df_tasks transformado')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-calgary",
   "metadata": {},
   "source": [
    "# <font color='blue'>monta tabelas dimensões</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-interim",
   "metadata": {},
   "source": [
    "## DIM acoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-library",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.421564Z",
     "start_time": "2021-03-16T12:59:40.416750Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_Acoes(df):\n",
    "\n",
    "    # trasnforma a coluna Acao em uma coluna do tipo \"category'\n",
    "    df['tmpAcao'] = df['Acao'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Ação\n",
    "    df['FK_dim_Acoes'] = df['tmpAcao'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_Acoes', 'Acao']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_Acao': 'PK_dim_Acao'}, inplace = True)\n",
    "    \n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['Acao'] == '', ['Acao']] = '<sem ação determinada>'\n",
    "    \n",
    "    # exclui a coluna Acoes de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Acao', 'tmpAcao'], axis=1, inplace=True)\n",
    "    \n",
    "    print('dim_Acoes montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-juice",
   "metadata": {},
   "source": [
    "## DIM categoria servicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medium-teaching",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.431216Z",
     "start_time": "2021-03-16T12:59:40.426421Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_CategoriaServico(df):\n",
    "\n",
    "    # trasnforma a coluna Categoria em uma coluna do tipo \"category'\n",
    "    df['tmpCategoria'] = df['Categoria'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão CategoriasServicos\n",
    "    df['FK_dim_CategoriasServicos'] = df['tmpCategoria'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_CategoriasServicos', 'Categoria']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_CategoriasServicos': 'PK_dim_CategoriasServicos'}, inplace = True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['Categoria'] == '', ['Categoria']] = '<categoria indefinida>'\n",
    "    \n",
    "    # exclui a coluna Categoria de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Categoria', 'tmpCategoria'], axis=1, inplace=True)\n",
    "    \n",
    "    print('dim_Categoria montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-things",
   "metadata": {},
   "source": [
    "## DIM encaminhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comic-cookbook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.439853Z",
     "start_time": "2021-03-16T12:59:40.434947Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_Encaminhamento(df):\n",
    "\n",
    "    # trasnforma a coluna EncaminhadoPara em uma coluna do tipo \"category'\n",
    "    df['tmpEncaminhadoPara'] = df['EncaminhadoPara'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Encaminhamento\n",
    "    df['FK_dim_Encaminhamento'] = df['tmpEncaminhadoPara'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_Encaminhamento', 'EncaminhadoPara']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_Encaminhamento': 'PK_dim_Encaminhamento'}, inplace = True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['EncaminhadoPara'] == '', ['EncaminhadoPara']] = '<sem encaminhamento>'\n",
    "\n",
    "    # exclui a coluna Entidade de df_tasks que será a futura tabela fato\n",
    "    df.drop(['EncaminhadoPara', 'tmpEncaminhadoPara'], axis=1, inplace=True)\n",
    "\n",
    "    print('dim_Encaminhamento montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-portland",
   "metadata": {},
   "source": [
    "## DIM entidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extraordinary-hungary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.448196Z",
     "start_time": "2021-03-16T12:59:40.443006Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_Entidade(df):\n",
    "\n",
    "\n",
    "    # trasnforma a coluna Entidade em uma coluna do tipo \"category'\n",
    "    df['tmpEntidade'] = df['Entidade'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Entidades\n",
    "    df['FK_dim_Entidades'] = df['tmpEntidade'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_Entidades', 'Entidade']].drop_duplicates()\n",
    "    dfx['Entidade'] = dfx['Entidade'].str.upper()\n",
    "    dfx.rename(columns={'FK_dim_Entidades': 'PK_dim_Entidades'}, inplace = True)\n",
    "\n",
    "    # exclui a coluna Entidade de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Entidade', 'tmpEntidade'], axis=1, inplace=True)\n",
    "\n",
    "    print('dim_Entidade montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-silicon",
   "metadata": {},
   "source": [
    "## DIM grupo responsavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "central-camera",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.454950Z",
     "start_time": "2021-03-16T12:59:40.450356Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_GrupoResponsavel(df):\n",
    "    \n",
    "    # trasnforma a coluna GrupoResponsavel em uma coluna do tipo \"category'\n",
    "    df['tmpGrupoResponsavel'] = df['GrupoResponsavel'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão GrupoResponsavel\n",
    "    df['FK_dim_GrupoResponsavel'] = df['tmpGrupoResponsavel'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_GrupoResponsavel', 'GrupoResponsavel']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_GrupoResponsavel': 'PK_dim_GrupoResponsavel'}, inplace = True)\n",
    "\n",
    "    # exclui a coluna GrupoResponsavel de df_tasks que será a futura tabela fato\n",
    "    df.drop(['GrupoResponsavel', 'tmpGrupoResponsavel'], axis=1, inplace=True)\n",
    "    \n",
    "    print('dim_GrupoResponsavel montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-sample",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:19:20.012078Z",
     "start_time": "2021-03-04T11:19:20.009504Z"
    }
   },
   "source": [
    "## DIM grupo usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "charged-france",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.461777Z",
     "start_time": "2021-03-16T12:59:40.457255Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_dim_GruposUsuarios(df):\n",
    "\n",
    "    # trasnforma a coluna Grupo em uma coluna do tipo \"category'\n",
    "    df['tmpGrupo'] = df['Grupo'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Grupo\n",
    "    df['FK_dim_GruposUsuarios'] = df['tmpGrupo'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_GruposUsuarios', 'Grupo']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_GruposUsuarios': 'PK_dim_GruposUsuarios'}, inplace = True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['Grupo'] == '', ['Grupo']] = '<grupo usuário não definido>'\n",
    "\n",
    "    # exclui a coluna Grupo de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Grupo', 'tmpGrupo'], axis=1, inplace=True)\n",
    "    \n",
    "    print('dim_GruposUsuarios montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-grenada",
   "metadata": {},
   "source": [
    "## DIM motivos cancelamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greatest-champagne",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.469026Z",
     "start_time": "2021-03-16T12:59:40.464302Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_MotivosCanc(df):\n",
    "\n",
    "\n",
    "    # trasnforma a coluna MotivoCancelamento em uma coluna do tipo \"category'\n",
    "    df['tmpMotivoCancelamento'] = df['MotivoCancelamento'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão MotivoCanc\n",
    "    df['FK_dim_MotivosCanc'] = df['tmpMotivoCancelamento'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_MotivosCanc', 'MotivoCancelamento']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_MotivosCanc': 'PK_dim_MotivosCanc'}, inplace = True)\n",
    "\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['MotivoCancelamento'] == '', ['MotivoCancelamento']] = '<sem motivo de cancelamento>'\n",
    "\n",
    "    # exclui a coluna MotivoCancelamento de df_tasks que será a futura tabela fato\n",
    "    df.drop(['MotivoCancelamento', 'tmpMotivoCancelamento'], axis=1, inplace=True)\n",
    "\n",
    "    print('dim_MotivosCanc montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-barbados",
   "metadata": {},
   "source": [
    "## DIM servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "weekly-universal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.476924Z",
     "start_time": "2021-03-16T12:59:40.471334Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_Servico(df, dff_sla):\n",
    "\n",
    "    # trasnforma a coluna Servico em uma coluna do tipo \"category'\n",
    "    df['tmpServico'] = df['Servico'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Servico\n",
    "    df['FK_dim_Servicos'] = df['tmpServico'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_Servicos', 'Servico']].drop_duplicates()\n",
    "\n",
    "    # exclui a coluna Servico de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Servico', 'tmpServico'], axis=1, inplace=True)\n",
    "\n",
    "    # defive os nomes das colunas de SLA\n",
    "    cols = {'FK_dim_Servicos': 'PK_dim_Servicos',\n",
    "            'Dentro do Prazo LMin': 'sla_VD_Lmin',\n",
    "            'Perto do Prazo LMin': 'sla_AM_Lmin',\n",
    "            'Fora do Prazo LMin': 'sla_VM_Lmin',\n",
    "            'Dentro do Prazo LMax': 'sla_VD_Lmax',\n",
    "            'Perto do Prazo LMax': 'sla_AM_LMax',\n",
    "            'Fora do Prazo LMax': 'sla_VM_LMax',\n",
    "           }\n",
    "    # faz um merge da dimensão dim_Servicos com a tabela de SLAs\n",
    "    dfx = dfx.merge(dff_sla, left_on='Servico', right_on='service', how='left')\n",
    "    dfx = dfx.drop('service', axis=1)\n",
    "    dfx.rename(columns=cols, inplace = True)\n",
    "    \n",
    "    print('dim_Servico montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-occurrence",
   "metadata": {},
   "source": [
    "## DIM status externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prompt-rebecca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.484460Z",
     "start_time": "2021-03-16T12:59:40.479588Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_StatusExt(df):\n",
    "\n",
    "    # trasnforma a coluna StatusExterno em uma coluna do tipo \"category'\n",
    "    df['tmpStatusExterno'] = df['StatusExterno'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Grupo\n",
    "    df['FK_dim_StatusExt'] = df['tmpStatusExterno'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_StatusExt', 'StatusExterno']].drop_duplicates()\n",
    "    dfx.rename(columns={'FK_dim_StatusExt': 'PK_dim_StatusExt'}, inplace = True)\n",
    "\n",
    "    # exclui a coluna Grupo de df_tasks que será a futura tabela fato\n",
    "    df.drop(['StatusExterno', 'tmpStatusExterno'], axis=1, inplace=True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['StatusExterno'] == '', ['StatusExterno']] = '<sem status>'\n",
    "\n",
    "    print('dim_StatusExt montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-textbook",
   "metadata": {},
   "source": [
    "## DIM usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "connected-theology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.491404Z",
     "start_time": "2021-03-16T12:59:40.486807Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_Usuarios(df):\n",
    "\n",
    "\n",
    "    # trasnforma a coluna Usuario em uma coluna do tipo \"category'\n",
    "    df['tmpUsuario'] = df['Usuarios'].astype('category')\n",
    "\n",
    "    # cria uma nova coluna que será a coluna chave primária da dimensão Usuario\n",
    "    df['FK_dim_Usuarios'] = df['tmpUsuario'].cat.codes.astype('int64') + 1\n",
    "\n",
    "    # tira a duplicidade\n",
    "    dfx = df.loc[:, ['FK_dim_Usuarios', 'Usuarios']].drop_duplicates()\n",
    "    col_ren = {'FK_dim_Usuarios': 'PK_dim_Usuarios', 'Usuarios': 'Usuario'}\n",
    "    dfx.rename(columns=col_ren, inplace = True)\n",
    "\n",
    "    # exclui a coluna Usuario de df_tasks que será a futura tabela fato\n",
    "    df.drop(['Usuarios', 'tmpUsuario'], axis=1, inplace=True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['Usuario'] == '', ['Usuario']] = '<usuário indefinido>'\n",
    "\n",
    "    print('dim_Usuario montada')\n",
    "    \n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-string",
   "metadata": {},
   "source": [
    "## DIM situacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "previous-third",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.497823Z",
     "start_time": "2021-03-16T12:59:40.493850Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_Situacao():\n",
    "\n",
    "    dfx = pd.DataFrame({'PK_dim_Situacao': [1, 2, 3],\n",
    "                        'Situacao':        ['em Andamento', 'Encerrada', 'Cancelada']}\n",
    "                        )\n",
    "    print('dim_Situacao montada')\n",
    "\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-click",
   "metadata": {},
   "source": [
    "## DIM SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reported-starter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.503382Z",
     "start_time": "2021-03-16T12:59:40.499965Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_SLA():\n",
    "\n",
    "    dfx = pd.DataFrame({'PK_dim_SLA': [1, 2, 3],\n",
    "                        'DescSLA':    ['dentro do prazo', 'perto do prazo', 'fora do prazo'],\n",
    "                        'Cor':        ['verde','amarelo' ,'vermelho']}\n",
    "                    )\n",
    "    print('dim_SLA montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-syndicate",
   "metadata": {},
   "source": [
    "## DIM endereco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broke-degree",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.513929Z",
     "start_time": "2021-03-16T12:59:40.505585Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_Endereco(df):\n",
    "\n",
    "    dict_uf = {'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas', 'BA': 'Bahia',\n",
    "               'CE': 'Ceará', 'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão', 'MT': 'Mato Grosso',\n",
    "               'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "               'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí', 'RJ': 'Rio de Janeiro',\n",
    "               'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul', 'RO': 'Rondônia', 'RR': 'Roraima',\n",
    "               'SC': 'Santa Catarina', 'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins', 'DF': 'Distrito Federal',\n",
    "               '<nd>': '<sem UF>'\n",
    "    }\n",
    "\n",
    "    # acrescenta o nome do estado ao dataframe\n",
    "    dfx = df.copy()\n",
    "    dfx['NomeUF'] = dfx['UF'].apply(lambda x: dict_uf.get(x, None))\n",
    "    dfx.rename(columns={'Solicitacao': 'PK_dim_Endereco'}, inplace = True)\n",
    "\n",
    "    # preenche colunas com linhas vazias\n",
    "    dfx.loc[dfx['CEP'].isna(), ['CEP']] = ''\n",
    "\n",
    "    print('dim_Endereco montada')\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-coordination",
   "metadata": {},
   "source": [
    "## FAT tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "violent-barbados",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.520659Z",
     "start_time": "2021-03-16T12:59:40.516948Z"
    }
   },
   "outputs": [],
   "source": [
    "# função retorna a situação da solicitação de acordo com as coilunas cancelado e encerrado\n",
    "def RetSit(Enc, Canc):\n",
    "    rt = 0\n",
    "    if Canc == 1:\n",
    "        rt = 3\n",
    "    elif Enc == 1:\n",
    "        rt = 2\n",
    "    else:\n",
    "        rt = 1\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "racial-religion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.532266Z",
     "start_time": "2021-03-16T12:59:40.522576Z"
    }
   },
   "outputs": [],
   "source": [
    "def Mt_Tasks(df, dfr):\n",
    "\n",
    "    dfx = df.copy()\n",
    "    \n",
    "    # faz um merge com o dataset de ratings\n",
    "    dfx = df.merge(dfr, left_on='Protocolo', right_on='Solicitacao', how='left')\n",
    "    dfx.drop(['Solicitacao'], axis=1, inplace=True)\n",
    "\n",
    "    # define o código de situação da solicitação\n",
    "    df_aux = dfx[['Protocolo', 'ProcessoEncerrado', 'ProcessoCancelado']].drop_duplicates()\n",
    "\n",
    "    # substui valores de colunas\n",
    "    troca = {'false': 0, 'true': 1}\n",
    "    df_aux['ProcessoEncerrado'] = df_aux['ProcessoEncerrado'].map(troca)\n",
    "    df_aux['ProcessoCancelado'] = df_aux['ProcessoCancelado'].map(troca)\n",
    "\n",
    "    # agrega as ações para um registro por protocolo\n",
    "    df_aux = df_aux.groupby('Protocolo').agg({'ProcessoEncerrado': 'max', 'ProcessoCancelado': 'max'}).reset_index()\n",
    "\n",
    "    # retorna a situção da solicitação: 1-em andamento, 2-encerrado, 3-cancelado\n",
    "    df_aux['Situacao'] = df_aux.apply(lambda x: RetSit(x['ProcessoEncerrado'], x['ProcessoCancelado']), axis=1)\n",
    "    df_aux.drop(['ProcessoEncerrado', 'ProcessoCancelado'], axis=1, inplace=True)\n",
    "\n",
    "    # faz merge com o dataset de situação da solicitação\n",
    "    dfx = dfx.merge(df_aux, left_on='Protocolo', right_on='Protocolo', how='left')\n",
    "    dfx.drop(['ProcessoEncerrado', 'ProcessoCancelado'], axis=1, inplace=True)\n",
    "\n",
    "    # coloca -1 para as solicitações que não possuem avaliação\n",
    "    dfx.loc[dfx['NotaAvaliacao'].isna(), 'NotaAvaliacao'] = -1\n",
    "    dfx['NotaAvaliacao'] = dfx['NotaAvaliacao'].astype('int32')\n",
    "\n",
    "    # renomeia as colunas\n",
    "    col_ren = {'Protocolo': 'FK_dim_Solicitacoes', 'Situacao': 'FK_dim_Situacao'}\n",
    "    dfx.rename(columns=col_ren, inplace = True)\n",
    "\n",
    "    # trata a coluna Prazo\n",
    "    dfx['Prazo'] == ''\n",
    "    dfx.loc[dfx['Prazo'] == '', 'Prazo'] = '0'\n",
    "    dfx['Prazo'] = dfx['Prazo'].astype('int64')\n",
    "\n",
    "    dfx['DataCriacao'] = pd.to_datetime(dfx['DataHora_Criacao']).dt.date\n",
    "    dfx['HoraCriacao'] = pd.to_datetime(dfx['DataHora_Criacao']).dt.time\n",
    "\n",
    "    dfx['DataConclusao'] = pd.to_datetime(dfx['DataHora_Conclusao']).dt.date\n",
    "    dfx['HoraConclusao'] = pd.to_datetime(dfx['DataHora_Conclusao']).dt.time\n",
    "\n",
    "    dfx.drop(['DataHora_Criacao', 'DataHora_Conclusao'], axis=1, inplace=True)\n",
    "\n",
    "    cols_ordem = ['FK_dim_Solicitacoes', 'Prazo', 'DataCriacao', 'HoraCriacao', \n",
    "                  'DataConclusao', 'HoraConclusao', \n",
    "                  'NotaAvaliacao', 'MotivoAvaliacao', \n",
    "                  'DataAvaliacao', 'HoraAvaliacao', \n",
    "                  'FK_dim_Entidades', 'FK_dim_Servicos', 'FK_dim_Usuarios', 'FK_dim_GruposUsuarios', \n",
    "                  'FK_dim_Acoes', 'FK_dim_StatusExt', 'FK_dim_CategoriasServicos', 'FK_dim_GrupoResponsavel', \n",
    "                  'FK_dim_MotivosCanc', 'FK_dim_Encaminhamento', 'FK_dim_Situacao'\n",
    "                ]\n",
    "    dfx = dfx[cols_ordem]\n",
    "\n",
    "    print('fat_Tasks montada')\n",
    "\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-break",
   "metadata": {},
   "source": [
    "# <font color='red'>4.0 LOAD</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "handed-genius",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.543638Z",
     "start_time": "2021-03-16T12:59:40.534992Z"
    }
   },
   "outputs": [],
   "source": [
    "def Load_BD(strAut):\n",
    "\n",
    "    # import the module\n",
    "    # create sqlalchemy engine\n",
    "    \n",
    "    SQLengine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                           .format(user = strAut['My_user'],\n",
    "                                   pw   = strAut['My_pw'],\n",
    "                                   host = strAut['My_host'],\n",
    "                                   db   = strAut['My_db']),\n",
    "                                   pool_recycle=3600)\n",
    "    dbConn = SQLengine.connect()\n",
    "\n",
    "    try:\n",
    "        df_dim_Acao.to_sql('dim_acoes', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Categoria.to_sql('dim_categorias_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Encaminhamento.to_sql('dim_encaminhamento', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Entidade.to_sql('dim_entidades', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_GrupoResponsavel.to_sql('dim_grupo_responsavel', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Grupo.to_sql('dim_grupos_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_MotivoCanc.to_sql('dim_motivos_canc', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Servicos.to_sql('dim_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_StatusExt.to_sql('dim_status_ext', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Usuarios.to_sql('dim_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Situacao.to_sql('dim_situacao', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_SLA.to_sql('dim_sla', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Endereco.to_sql('dim_endereco', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "        df_fat_tasks.to_sql('fat_tasks', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "    except ValueError as vx:\n",
    "        print('ERROR -', vx)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print('EXCEPTION -', ex)\n",
    "\n",
    "    else:\n",
    "        print('Tabelas criadas com sucesso');  \n",
    "\n",
    "    finally:\n",
    "        dbConn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-asian",
   "metadata": {},
   "source": [
    "# <font color='red'>0.0 MAIN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "contemporary-leone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:40.553863Z",
     "start_time": "2021-03-16T12:59:40.549494Z"
    }
   },
   "outputs": [],
   "source": [
    "# monta as strings de conexão\n",
    "def StrConn(sit):\n",
    "    in_oper   = {'My_host': 'localhost', 'My_db': 'bd_fontes',       'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    out_oper  = {'My_host': 'localhost', 'My_db': 'bd_dw',           'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    in_teste  = {'My_host': 'localhost', 'My_db': 'bd_teste_fontes', 'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    out_teste = {'My_host': 'localhost', 'My_db': 'bd_teste_dw',     'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    \n",
    "    # se True é teste\n",
    "    if sit:\n",
    "        rt_in = in_teste\n",
    "        rt_out = out_teste\n",
    "    else:\n",
    "        rt_in = in_oper\n",
    "        rt_out = out_oper\n",
    "\n",
    "    return rt_in, rt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "instructional-campbell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:59:41.227505Z",
     "start_time": "2021-03-16T12:59:40.556075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks:619 registros lidos em 16 colunas\n",
      "sla: 54 registros lidos em 5 colunas\n",
      "form: 750 registros lidos em 3 colunas\n",
      "rating: 30 registros lidos em 4 colunas\n",
      "MySQL connection is closed\n",
      "df_sla transformado\n",
      "df_form transformado\n",
      "df_rating transformado\n",
      "df_tasks transformado\n",
      "dim_Acoes montada\n",
      "dim_Categoria montada\n",
      "dim_Encaminhamento montada\n",
      "dim_Entidade montada\n",
      "dim_GrupoResponsavel montada\n",
      "dim_GruposUsuarios montada\n",
      "dim_MotivosCanc montada\n",
      "dim_Servico montada\n",
      "dim_StatusExt montada\n",
      "dim_Usuario montada\n",
      "dim_Situacao montada\n",
      "dim_SLA montada\n",
      "dim_Endereco montada\n",
      "fat_Tasks montada\n",
      "Tabelas criadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    etl_teste = False\n",
    "\n",
    "    # EXTRACT\n",
    "    AUTENTIC_IN, AUTENTIC_OUT = StrConn(etl_teste)\n",
    "    df_tasks, df_sla, df_form, df_rating = LeFontes(AUTENTIC_IN)\n",
    "    \n",
    "    # TRANSFORM\n",
    "    # trata os datasets\n",
    "    df_sla    = trSLA(df_sla)\n",
    "    df_form   = trForm(df_form)\n",
    "    df_rating = trRating(df_rating)\n",
    "    df_tasks  = trTasks(df_tasks)\n",
    "    \n",
    "    # monta as tabelas dimensão\n",
    "    df_dim_Acao              = Mt_dim_Acoes(df_tasks)\n",
    "    df_dim_Categoria         = Mt_dim_CategoriaServico(df_tasks)\n",
    "    df_dim_Encaminhamento    = Mt_dim_Encaminhamento(df_tasks)\n",
    "    df_dim_Entidade          = Mt_dim_Entidade(df_tasks)\n",
    "    df_dim_GrupoResponsavel  = Mt_dim_GrupoResponsavel(df_tasks)\n",
    "    df_dim_Grupo             = Mt_dim_GruposUsuarios(df_tasks)\n",
    "    df_dim_MotivoCanc        = Mt_MotivosCanc(df_tasks)\n",
    "    df_dim_Servicos          = Mt_Servico(df_tasks, df_sla)\n",
    "    df_dim_StatusExt         = Mt_StatusExt(df_tasks)\n",
    "    df_dim_Usuarios          = Mt_Usuarios(df_tasks)\n",
    "    df_dim_Situacao          = Mt_Situacao()\n",
    "    df_dim_SLA               = Mt_SLA()\n",
    "    df_dim_Endereco          = Mt_Endereco(df_form)\n",
    "    \n",
    "    # monta a tabela fato\n",
    "    df_fat_tasks             = Mt_Tasks(df_tasks, df_rating)\n",
    "    \n",
    "    # monta as tabelas dimensão do META BI\n",
    "    \n",
    "    \n",
    "    # LOAD\n",
    "    ret = Load_BD(AUTENTIC_OUT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-checkout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
