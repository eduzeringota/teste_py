{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>ALPAR - Governo Digital - Processo Inteligente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>ETL para o BI</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.0 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.106846Z",
     "start_time": "2021-03-30T11:49:49.104160Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.115020Z",
     "start_time": "2021-03-30T11:49:49.110617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import errorcode# import numpy as np\n",
    "# import copy\n",
    "# import csv\n",
    "# import codecs\n",
    "# import time\n",
    "# from os.path import expanduser\n",
    "\n",
    "\n",
    "\n",
    "# print(\"pandas versão\", pd.__version__)\n",
    "# print(\"numpy versão\", np.__version__)\n",
    "# print(\"csv versão\", csv.__version__)\n",
    "\n",
    "# pd.options.display.max_rows = 2000\n",
    "# pd.options.display.width = 120\n",
    "# pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font color='black'>2.0 load datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.122668Z",
     "start_time": "2021-03-30T11:49:49.119197Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "My_host = 'localhost'\n",
    "My_db = 'bd_fontes'\n",
    "My_user = 'gd'\n",
    "My_pw = 'Alpar@123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.129987Z",
     "start_time": "2021-03-30T11:49:49.126591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sql_form = (\n",
    "\"SELECT * \"\n",
    "\"FROM form\"\n",
    ")\n",
    "sql_tasks = (\n",
    "\"SELECT \"\n",
    "\"Protocolo as 'protocolo', \"\n",
    "\"Entidade as 'entidade', \"\n",
    "\"`Data e Hora de criação` as 'data_hora_criacao' \"\n",
    "\"FROM tasks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.182204Z",
     "start_time": "2021-03-30T11:49:49.132858Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 registros lidos em 7 colunas\n",
      "619 registros lidos em 3 colunas\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(host = My_host, database = My_db, user = My_user, password = My_pw)\n",
    "    \n",
    "    df_form = pd.read_sql(sql_form, con=connection)\n",
    "    df_tasks = pd.read_sql(sql_tasks, con=connection)\n",
    "    \n",
    "except mysql.connector.Error as error:\n",
    "    print(\"Failed to read record from MySQL table {}\".format(error))\n",
    "\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        print(f'{df_form.shape[0]} registros lidos em {df_form.shape[1]} colunas')\n",
    "        print(f'{df_tasks.shape[0]} registros lidos em {df_tasks.shape[1]} colunas')\n",
    "\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>3.0 prepara tabelas auxiliares</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 prepara tabela auxiliar tasks (Z_aux_entidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.191670Z",
     "start_time": "2021-03-30T11:49:49.184631Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux_entidade = df_tasks[['protocolo', 'entidade']].drop_duplicates()\n",
    "# df_aux_entidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 prepara tabela BASE (Z_aux_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.201010Z",
     "start_time": "2021-03-30T11:49:49.196387Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux_BASE = df_form.copy()\n",
    "df_aux_BASE.columns = ['atributo', 'nome', 'valor', 'protocolo', 'servico', 'tipo', 'campo_relacionado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.220525Z",
     "start_time": "2021-03-30T11:49:49.204937Z"
    }
   },
   "outputs": [],
   "source": [
    "# transforma as strings atributo e campo relacionado em lower case\n",
    "df_aux_BASE[['atributo', 'campo_relacionado']] = df_aux_BASE[['atributo', 'campo_relacionado']].apply(lambda x: x.str.lower())\n",
    "# df_aux_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.229547Z",
     "start_time": "2021-03-30T11:49:49.222797Z"
    }
   },
   "outputs": [],
   "source": [
    "# faz um merge da dimensão df_aux_BASE com a df_auxentidade para adicionar a coluna entidade\n",
    "# se não existir o protocolo na tasks não considera a linha -- isso é um erro de integridade da base de dados\n",
    "df_aux_BASE = df_aux_BASE.merge(df_aux_entidade, on='protocolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.244936Z",
     "start_time": "2021-03-30T11:49:49.232038Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria 3 novas colunas vazias\n",
    "df_aux_BASE['MET_atributo'] = np.nan\n",
    "df_aux_BASE['MET_valor'] = np.nan\n",
    "df_aux_BASE['MET_tipo'] = np.nan\n",
    "\n",
    "# cria uma coluna como PK\n",
    "df_aux_BASE['PK'] = df_aux_BASE['entidade'] + '_' + df_aux_BASE['servico'] + '_' + \\\n",
    "                    df_aux_BASE['atributo'] + '_' + df_aux_BASE['protocolo']\n",
    "\n",
    "# cria uma coluna com o tipo de registro\n",
    "df_aux_BASE['TIPO_REG'] = 'BASE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 prepara tabela MET (Z_aux_MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.250579Z",
     "start_time": "2021-03-30T11:49:49.246914Z"
    }
   },
   "outputs": [],
   "source": [
    "def Enumerico(s, tipo):\n",
    "    try:\n",
    "        v = np.float64(s) if tipo == 'DOUBLE' else np.int64(s)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.257492Z",
     "start_time": "2021-03-30T11:49:49.253299Z"
    }
   },
   "outputs": [],
   "source": [
    "def GeraCodDimMet(d, m):\n",
    "    d_dim = {'STRING_DIM': 10, 'BOOLEAN_DIM': 20, 'INTEGER_DIM' :30, 'DOUBLE_DIM': 40, 'ID_DIM': 50}\n",
    "    d_met = {'INTEGER_MET': 1, 'DOUBLE_MET': 2, 'NULL_MET': 3}\n",
    "\n",
    "    v_dim = d_dim[d] if d in d_dim else 0\n",
    "    v_met = d_met[m] if m in d_met else 0\n",
    "    \n",
    "    return v_dim + v_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.287061Z",
     "start_time": "2021-03-30T11:49:49.260018Z"
    }
   },
   "outputs": [],
   "source": [
    "# traramento do tipo INTEGER ou DOUBLE\n",
    "\n",
    "# dataset de métricas - usa somente tipo \"INTEGER\" ou \"DOUBLE\"\n",
    "cols = ['atributo', 'nome', 'valor', 'protocolo', 'servico', 'tipo', 'campo_relacionado', 'entidade']\n",
    "df_aux_MET = df_aux_BASE.loc[(df_aux_BASE['tipo'] == 'INTEGER') | (df_aux_BASE['tipo'] == 'DOUBLE'), cols].copy()\n",
    "\n",
    "# os valores estão com formato: ponto para separador de milhar e vírgula para fração\n",
    "# tira os pontos separador de milhar e substitui vírgula por ponto\n",
    "df_aux_MET['valor'] = df_aux_MET['valor'].apply(lambda x: x.replace('.', '').replace(',', '.'))\n",
    "\n",
    "# alimenta uma coluna indicadora que mostra se o valor corresponde ou não ao tipo\n",
    "df_aux_MET['numerico'] = df_aux_MET.apply(lambda x: Enumerico(x['valor'], x['tipo']), axis=1)\n",
    "\n",
    "# cria um dataset de linhas cuja o valor não corresponde ao tipo\n",
    "df_aux_MET_Err = df_aux_MET[df_aux_MET['numerico'] == False].drop('numerico', axis=1)\n",
    "\n",
    "# cria um dataset de linhas de métricas\n",
    "df_aux_MET = df_aux_MET[~df_aux_MET['numerico'] == False].drop('numerico', axis=1)\n",
    "\n",
    "# identifica que esse é um dataset de métricas\n",
    "df_aux_MET['TIPO_REG'] = 'MET'\n",
    "\n",
    "# exclui linhas que não seja uma métrica explícita\n",
    "df_aux_MET = df_aux_MET[~(df_aux_MET['campo_relacionado'] == 'null')]\n",
    "\n",
    "# cria a coluna FK para relacionar com o dataset BASE\n",
    "df_aux_MET['FK'] = df_aux_MET['entidade'] + '_' + df_aux_MET['servico'] + '_' + \\\n",
    "                   df_aux_MET['campo_relacionado'] + '_' + df_aux_MET['protocolo']\n",
    "\n",
    "# troca o nome de algumas colunas\n",
    "dc = {'atributo': 'MET_atributo', 'campo_relacionado': 'atributo', 'valor': 'MET_valor', 'tipo': 'MET_tipo'}\n",
    "df_aux_MET.rename(columns=dc, inplace = True)\n",
    "\n",
    "# faz um merge com o dataset BASE \n",
    "df_aux_MET = df_aux_MET.merge(df_aux_BASE[['PK', 'valor', 'tipo']], left_on='FK', right_on='PK')\n",
    "df_aux_MET.drop(['PK', 'FK'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 prepara tabela DIM (Z_aux_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.297341Z",
     "start_time": "2021-03-30T11:49:49.289183Z"
    }
   },
   "outputs": [],
   "source": [
    "# escolee as colunas que farão a cancatenação de dataframes\n",
    "cols = ['atributo', 'nome', 'valor', 'protocolo', 'servico', 'tipo', \n",
    "        'entidade', 'MET_atributo', 'MET_valor', 'MET_tipo', 'TIPO_REG']\n",
    "df_aux_DIM = df_aux_BASE[cols].copy()\n",
    "df_aux_DIM = pd.concat([df_aux_DIM, df_aux_MET])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 prepara tabela de decisão (Z_aux_decisao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.309203Z",
     "start_time": "2021-03-30T11:49:49.299189Z"
    }
   },
   "outputs": [],
   "source": [
    "mtx =  [('STRING_DIM',  'INTEGER_MET', 'N', 'N', 'S', 'S'),\n",
    "        ('STRING_DIM',  'DOUBLE_MET',  'N', 'N', 'S', 'S'),\n",
    "        ('STRING_DIM',  'NULL_MET',    'S', 'S', 'N', 'N'),\n",
    "        \n",
    "        ('BOOLEAN_DIM', 'INTEGER_MET', 'S', 'N', 'N', 'N'),\n",
    "        ('BOOLEAN_DIM', 'DOUBLE_MET',  'S', 'N', 'N', 'N'),\n",
    "        ('BOOLEAN_DIM', 'NULL_MET',    'S', 'N', 'N', 'N'),\n",
    "        \n",
    "        ('INTEGER_DIM', 'INTEGER_MET', 'S', 'S', 'S', 'S'),\n",
    "        ('INTEGER_DIM', 'DOUBLE_MET',  'N', 'N', 'N', 'N'),\n",
    "        ('INTEGER_DIM', 'NULL_MET',    'S', 'S', 'N', 'N'),\n",
    "        \n",
    "        ('DOUBLE_MET',  'INTEGER_MET', 'N', 'N', 'N', 'N'),\n",
    "        ('DOUBLE_MET',  'DOUBLE_MET',  'N', 'N', 'S', 'S'),\n",
    "        ('DOUBLE_MET',  'NULL_MET',    'N', 'N', 'N', 'N'),\n",
    "        \n",
    "        ('ID_DIM',      'INTEGER_MET', 'N', 'N', 'S', 'S'),\n",
    "        ('ID_DIM',      'DOUBLE_MET',  'N', 'N', 'S', 'S'),\n",
    "        ('ID_DIM',      'NULL_MET',    'S', 'S', 'N', 'N')\n",
    "       ]\n",
    "cols_mtx = ['t_dim', 't_met', 'Count', 'Distinct Count', 'Sum', 'Average']\n",
    "\n",
    "df_aux_dec = pd.DataFrame(mtx, columns=cols_mtx)\n",
    "df_aux_dec['Cod_Decisao'] = df_aux_dec.apply(lambda x:\n",
    "                                    GeraCodDimMet(x['t_dim'], x['t_met']), axis=1)\n",
    "\n",
    "# df_aux_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 ponte de decisão da operação (Z_pto_decisao_operacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.326970Z",
     "start_time": "2021-03-30T11:49:49.311723Z"
    }
   },
   "outputs": [],
   "source": [
    "# faz uma cópia da tabela de decisão com as colunas necessárias\n",
    "cols = ['Cod_Decisao'] + cols_mtx[2:]\n",
    "df_aux_pto = df_aux_dec[cols].copy()\n",
    "\n",
    "# faz o unpivot\n",
    "df_aux_pto = pd.melt(df_aux_pto, id_vars=['Cod_Decisao'], \n",
    "                 value_vars=['Count', 'Distinct Count', 'Sum', 'Average'],\n",
    "                 var_name='Atributo')\n",
    "df_aux_pto = df_aux_pto[df_aux_pto['value'] == 'S'].drop('value', axis=1)\n",
    "\n",
    "# trasnforma a coluna Atributo em uma coluna do tipo \"category'\n",
    "df_aux_pto['Atributo'] = df_aux_pto['Atributo'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Operação\n",
    "df_aux_pto['FK_ZN_dim_OPERACAO'] = df_aux_pto['Atributo'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# cria a tabela df_pto_decisao_operacao necessária ao modelo dimensional\n",
    "df_pto_decisao_operacao = df_aux_pto[['Cod_Decisao', 'FK_ZN_dim_OPERACAO']]\n",
    "df_pto_decisao_operacao.columns = ['FK_dim_DECISAO', 'FK_ZN_dim_OPERACAO']\n",
    "# df_pto_decisao_operacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 tabela auxiliar das Datas das Solicitações (Z_aux_DataSolicitacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.372309Z",
     "start_time": "2021-03-30T11:49:49.329051Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria uma coluna só de datas\n",
    "df_tasks['data_criacao'] = pd.to_datetime(df_tasks['data_hora_criacao']).dt.date\n",
    "\n",
    "# pega a menor data de cada número de protocolo\n",
    "df_aux_DataSolicitacao = df_tasks[['protocolo', 'data_criacao']].groupby('protocolo').agg('min').reset_index()\n",
    "# df_aux_DataSolicitacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>4.0 monta tabelas dimensões</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 monta Z_dim_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.414887Z",
     "start_time": "2021-03-30T11:49:49.398597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PK_Z_dim_DIM</th>\n",
       "      <th>dimensao</th>\n",
       "      <th>nome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>Nome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cpf</td>\n",
       "      <td>Cpf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cnpj</td>\n",
       "      <td>Cnpj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>street</td>\n",
       "      <td>Logradouro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>possuiplanomunicipaldeeducacaopermanentedosuas</td>\n",
       "      <td>Possui Plano Municipal de Educação Permanente ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>atuouemtematicasprevistasnoplanomunicipaldeedu...</td>\n",
       "      <td>Atuou em temáticas previstas no Plano Municipa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>participoudecapacitacoesrealizadaspelasedesnos...</td>\n",
       "      <td>Participou de capacitações realizadas pela SED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>cofinanciamentoestadual</td>\n",
       "      <td>Co-financiamento Estadual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>descricaodoitem</td>\n",
       "      <td>Quantidade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PK_Z_dim_DIM                                           dimensao  \\\n",
       "0              1                                               name   \n",
       "1              2                                              email   \n",
       "2              3                                                cpf   \n",
       "3              4                                               cnpj   \n",
       "4              5                                             street   \n",
       "..           ...                                                ...   \n",
       "61            62     possuiplanomunicipaldeeducacaopermanentedosuas   \n",
       "62            63  atuouemtematicasprevistasnoplanomunicipaldeedu...   \n",
       "63            64  participoudecapacitacoesrealizadaspelasedesnos...   \n",
       "64            65                            cofinanciamentoestadual   \n",
       "65            66                                    descricaodoitem   \n",
       "\n",
       "                                                 nome  \n",
       "0                                                Nome  \n",
       "1                                               email  \n",
       "2                                                 Cpf  \n",
       "3                                                Cnpj  \n",
       "4                                          Logradouro  \n",
       "..                                                ...  \n",
       "61  Possui Plano Municipal de Educação Permanente ...  \n",
       "62  Atuou em temáticas previstas no Plano Municipa...  \n",
       "63  Participou de capacitações realizadas pela SED...  \n",
       "64                          Co-financiamento Estadual  \n",
       "65                                         Quantidade  \n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_dim = df_aux_DIM[['atributo', 'nome']].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "df_dim_dim.columns = ['PK_Z_dim_DIM', 'dimensao', 'nome']\n",
    "df_dim_dim['PK_Z_dim_DIM'] += 1\n",
    "# df_dim_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 monta Z_dim_SERVICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.430395Z",
     "start_time": "2021-03-30T11:49:49.416966Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dim_servico = df_aux_DIM['servico'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "df_dim_servico.columns = ['PK_Z_dim_SERVICO', 'servico']\n",
    "df_dim_servico['PK_Z_dim_SERVICO'] += 1\n",
    "# df_dim_servico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 monta Z_dim_MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.442455Z",
     "start_time": "2021-03-30T11:49:49.433710Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dim_met = df_aux_DIM.loc[~df_aux_DIM['MET_atributo'].isna(), 'MET_atributo'].drop_duplicates()\n",
    "df_dim_met = df_dim_met.reset_index(drop=True).reset_index()\n",
    "df_dim_met.columns = ['PK_Z_dim_MET', 'metrica']\n",
    "df_dim_met['PK_Z_dim_MET'] += 1\n",
    "# df_dim_met\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 monta Z_dim_OPERACAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.451015Z",
     "start_time": "2021-03-30T11:49:49.445780Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ZN_dim_OPERACAO = df_aux_pto[['FK_ZN_dim_OPERACAO', 'Atributo']].drop_duplicates()\n",
    "df_ZN_dim_OPERACAO.columns = ['PK_Z_dim_OPERACAO', 'operacao']\n",
    "# df_ZN_dim_OPERACAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 monta Z_dim_DECISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:49:49.458208Z",
     "start_time": "2021-03-30T11:49:49.453294Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dim_dec = df_aux_dec[['Cod_Decisao', 't_dim', 't_met']].copy().rename(columns={'Cod_Decisao': 'PK_Z_dim_DECISAO'})\n",
    "# df_dim_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 monta Z_fat_BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T13:46:31.601921Z",
     "start_time": "2021-03-30T13:46:31.531552Z"
    }
   },
   "outputs": [],
   "source": [
    "# copia o df auxiliar\n",
    "df_fat_B = df_aux_DIM.copy()\n",
    "\n",
    "# faz merge com dim_DIM\n",
    "df_fat_B = df_fat_B.merge(df_dim_dim, \n",
    "                          how='left', \n",
    "                          left_on=['atributo', 'nome'], \n",
    "                          right_on=['dimensao', 'nome']).drop(['atributo', 'nome', 'dimensao'], axis=1)\n",
    "# faz merge com dim_SERVICO\n",
    "df_fat_B = df_fat_B.merge(df_dim_servico, \n",
    "                          how='left', \n",
    "                          left_on='servico', \n",
    "                          right_on='servico').drop('servico', axis=1)\n",
    "# faz merge com dim_MET\n",
    "df_fat_B = df_fat_B.merge(df_dim_met, \n",
    "                          how='left', \n",
    "                          left_on='MET_atributo', \n",
    "                          right_on='metrica').drop(['MET_atributo', 'metrica'], axis=1)\n",
    "# faz merge com Z_aux_DataSolicitacao\n",
    "df_fat_B = df_fat_B.merge(df_aux_DataSolicitacao, \n",
    "                          how='left', \n",
    "                          on='protocolo') #.drop(['MET_atributo', 'metrica'], axis=1)\n",
    "\n",
    "# cria a coluna indicadora de NULL_MET\n",
    "df_fat_B['reg_nativo'] = df_fat_B['MET_tipo'].apply(lambda x: 1 if pd.isna(x) else 0)\n",
    "\n",
    "# passa as colunas de tipo para a string indicadora de NULL\n",
    "df_fat_B.loc[df_fat_B['MET_tipo'].isna(), 'MET_tipo'] = 'NULL_MET'\n",
    "df_fat_B.loc[df_fat_B['tipo'].isna(), 'tipo'] = 'NULL_DIM'\n",
    "\n",
    "\n",
    "# substitui valores da coluna tipo\n",
    "subs_dim = {'STRING':'STRING_DIM', \n",
    "            'INTEGER': 'INTEGER_DIM', \n",
    "            'BOOLEAN':'BOOLEAN_DIM', \n",
    "            'DOUBLE': 'DOUBLE_DIM',\n",
    "            'ID':'ID_DIM'}\n",
    "subs_met = {'INTEGER': 'INTEGER_MET', \n",
    "            'DOUBLE': 'DOUBLE_MET'}\n",
    "\n",
    "df_fat_B['tipo'].replace(subs_dim, inplace=True)\n",
    "df_fat_B['MET_tipo'].replace(subs_met, inplace=True)\n",
    "\n",
    "# acha o código para a tabela de decisão da dupla de tipos como FK para a PK de \"df_aux_dec\"\n",
    "df_fat_B['FK_dim_DECISAO'] = df_fat_B.apply(lambda x:\n",
    "                                    GeraCodDimMet(x['tipo'], x['MET_tipo']), axis=1)\n",
    "\n",
    "# exclui colunas já usadas\n",
    "df_fat_B.drop(['tipo', 'MET_tipo'], axis=1, inplace=True)\n",
    "\n",
    "# acerta os nomes das colunas\n",
    "dc = {'PK_Z_dim_DIM': 'FK_Z_dim_DIM', \n",
    "      'PK_Z_dim_SERVICO': 'FK_Z_dim_SERVICO', \n",
    "      'PK_Z_dim_MET': 'FK_Z_dim_MET', \n",
    "      'data_criacao': 'FK_Data_Criacao'}\n",
    "df_fat_B.rename(columns=dc, inplace = True)\n",
    "\n",
    "# acerta os tipos das colunas\n",
    "df_fat_B['FK_Z_dim_MET'] = df_fat_B['FK_Z_dim_MET'].astype('Int64')\n",
    "df_fat_B['MET_valor'] = df_fat_B['MET_valor'].astype('float64')\n",
    "df_fat_B['FK_Data_Criacao'] = df_fat_B['FK_Data_Criacao'].apply(pd.to_datetime)\n",
    "\n",
    "# df_fat_B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grava no MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monta as strings de conexão\n",
    "def StrConn(sit):\n",
    "    in_oper   = {'My_host': 'localhost', 'My_db': 'bd_fontes',       'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    out_oper  = {'My_host': 'localhost', 'My_db': 'bd_dw',           'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    in_teste  = {'My_host': 'localhost', 'My_db': 'bd_teste_fontes', 'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    out_teste = {'My_host': 'localhost', 'My_db': 'bd_teste_dw',     'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "    \n",
    "    # se True é teste\n",
    "    if sit:\n",
    "        rt_in = in_teste\n",
    "        rt_out = out_teste\n",
    "    else:\n",
    "        rt_in = in_oper\n",
    "        rt_out = out_oper\n",
    "\n",
    "    return rt_in, rt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_BD(strAut):\n",
    "\n",
    "    # import the module\n",
    "    # create sqlalchemy engine\n",
    "    \n",
    "    SQLengine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                           .format(user = strAut['My_user'],\n",
    "                                   pw   = strAut['My_pw'],\n",
    "                                   host = strAut['My_host'],\n",
    "                                   db   = strAut['My_db']),\n",
    "                                   pool_recycle=3600)\n",
    "    dbConn = SQLengine.connect()\n",
    "\n",
    "    try:\n",
    "        df_dim_Acao.to_sql('dim_acoes', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Categoria.to_sql('dim_categorias_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Encaminhamento.to_sql('dim_encaminhamento', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Entidade.to_sql('dim_entidades', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_GrupoResponsavel.to_sql('dim_grupo_responsavel', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Grupo.to_sql('dim_grupos_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_MotivoCanc.to_sql('dim_motivos_canc', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Servicos.to_sql('dim_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_StatusExt.to_sql('dim_status_ext', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Usuarios.to_sql('dim_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Situacao.to_sql('dim_situacao', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_SLA.to_sql('dim_sla', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "        df_dim_Endereco.to_sql('dim_endereco', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "        df_fat_tasks.to_sql('fat_tasks', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "    except ValueError as vx:\n",
    "        print('ERROR -', vx)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print('EXCEPTION -', ex)\n",
    "\n",
    "    else:\n",
    "        print('Tabelas criadas com sucesso');  \n",
    "\n",
    "    finally:\n",
    "        dbConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
