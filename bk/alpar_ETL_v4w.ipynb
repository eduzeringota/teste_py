{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>ALPAR - Governo Digital - Processo Inteligente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>ETL para o BI</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>1.0 ENVIRONMENT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>importação de pacotes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.063163Z",
     "start_time": "2021-03-04T11:12:39.626831Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install mysql-connector-python\n",
    "# !pip install pymysql\n",
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pd.options.display.max_rows = 2000\n",
    "# pd.options.display.width = 120\n",
    "# pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>constantes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.073454Z",
     "start_time": "2021-03-04T11:12:41.069018Z"
    }
   },
   "outputs": [],
   "source": [
    "MINUTOS_PARA_DIAS = 1440 # quantidade de minutos em um dia\n",
    "AUTENTIC_IN = {'My_host': 'localhost', 'My_db': 'bd_fontes', 'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "# AUTENTIC_IN = {'My_host': 'localhost', 'My_db': 'bd_teste_fontes', 'My_user': 'gd', 'My_pw': 'Alpar@123'}\n",
    "AUTENTIC_OUT = {'My_host': 'localhost', 'My_db': 'bd_teste_dw', 'My_user': 'gd', 'My_pw': 'Alpar@123'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>2.0 EXTRACT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset tasks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.097638Z",
     "start_time": "2021-03-04T11:12:41.086603Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_form = (\n",
    "\"SELECT `atributo`, `valor`, `protocolo` \"\n",
    "\"FROM form \"\n",
    "\"WHERE `atributo` IN ('state', 'city', 'neighborhood', 'zipcode', 'street')\"\n",
    ")\n",
    "sql_tasks = (\n",
    "\"SELECT `Protocolo`, `Entidade`, `Serviço`, `Usuário`, `Grupo`, `Data e Hora de conclusão`, \"\n",
    "\"`Data e Hora de criação`, `Ação`, `Encaminhado para`, `Processo encerrado`, `Processo cancelado`, \"\n",
    "\"`Motivo de cancelamento`, `Status externo`, `Categoria`, `Grupo responsável`, `Prazo (em segundos)` \"\n",
    "\"FROM tasks\"\n",
    ")\n",
    "sql_sla = (\n",
    "\"SELECT * \"\n",
    "\"FROM sla\"\n",
    ")\n",
    "sql_rating = (\n",
    "\"SELECT * \"\n",
    "\"FROM rating\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.246604Z",
     "start_time": "2021-03-04T11:12:41.123093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks:382 registros lidos em 16 colunas\n",
      "sla: 21 registros lidos em 5 colunas\n",
      "form: 420 registros lidos em 3 colunas\n",
      "rating: 30 registros lidos em 4 colunas\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(host =     AUTENTIC_IN['My_host'], \n",
    "                                         database = AUTENTIC_IN['My_db'], \n",
    "                                         user =     AUTENTIC_IN['My_user'], \n",
    "                                         password = AUTENTIC_IN['My_pw'])\n",
    "\n",
    "    df_tasks =   pd.read_sql(sql_tasks,  con=connection)\n",
    "    df_sla =     pd.read_sql(sql_sla,    con=connection)\n",
    "    df_form =    pd.read_sql(sql_form,   con=connection)\n",
    "    df_rating =  pd.read_sql(sql_rating, con=connection)\n",
    "    \n",
    "except mysql.connector.Error as error:\n",
    "    print(\"Failed to read record from MySQL table {}\".format(error))\n",
    "\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        print(f'tasks:{df_tasks.shape[0]} registros lidos em {df_tasks.shape[1]} colunas')\n",
    "        print(f'sla: {df_sla.shape[0]} registros lidos em {df_sla.shape[1]} colunas')\n",
    "        print(f'form: {df_form.shape[0]} registros lidos em {df_form.shape[1]} colunas')\n",
    "        print(f'rating: {df_rating.shape[0]} registros lidos em {df_rating.shape[1]} colunas')\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>3.0 TRANSFORM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset sla</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.269981Z",
     "start_time": "2021-03-04T11:12:41.256083Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sla_1 = df_sla.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.326093Z",
     "start_time": "2021-03-04T11:12:41.287723Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche com null as colunas que contém 'null' como tipo string\n",
    "df_sla_1.loc[(df_sla_1['limiteMinimo'] == 'null'), 'limiteMinimo'] = np.nan\n",
    "df_sla_1.loc[(df_sla_1['limiteMaximo'] == 'null'), 'limiteMaximo'] = np.nan\n",
    "\n",
    "# transforma o tipo de coluna para float\n",
    "df_sla_1['limiteMinimo'] = df_sla_1['limiteMinimo'].astype(float)\n",
    "df_sla_1['limiteMaximo'] = df_sla_1['limiteMaximo'].astype(float)\n",
    "\n",
    "# transforma a unidade de medida de minuto para dias\n",
    "df_sla_1['limiteMinimo'] = df_sla_1['limiteMinimo'] / MINUTOS_PARA_DIAS\n",
    "df_sla_1['limiteMaximo'] = df_sla_1['limiteMaximo'] / MINUTOS_PARA_DIAS\n",
    "\n",
    "# preenche com valores extremos os limites máximos e limites mínimos\n",
    "df_sla_1.loc[(df_sla_1['limiteMinimo'].isna()), 'limiteMinimo'] = -9999999.9\n",
    "df_sla_1.loc[(df_sla_1['limiteMaximo'].isna()), 'limiteMaximo'] = 9999999.9\n",
    "\n",
    "# cria mais uma coluna de status para pivotar limite mínimo e limite máxio\n",
    "df_sla_1['status2'] = df_sla_1['status']\n",
    "df_sla_1.rename(columns={'status': 'StatusLmin', 'status2': 'StatusLmax'}, inplace = True)\n",
    "\n",
    "# df_sla_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.387954Z",
     "start_time": "2021-03-04T11:12:41.339761Z"
    }
   },
   "outputs": [],
   "source": [
    "# faz pivot da coluna StatusLmin\n",
    "idx = ['entityCode', 'service', 'StatusLmax', 'limiteMaximo']\n",
    "df_sla_1 = df_sla_1.pivot(columns = 'StatusLmin', values = 'limiteMinimo', index=idx).reset_index()\n",
    "df_sla_1.columns.name = None\n",
    "dic_renome = {'Dentro do prazo' : 'Dentro do Prazo LMin', \n",
    "              'Fora do prazo' : 'Fora do Prazo LMin',\n",
    "              'Perto do prazo' : 'Perto do Prazo LMin'}\n",
    "df_sla_1.rename(columns=dic_renome, inplace = True)\n",
    "\n",
    "# faz pivot da coluna StatusLmax\n",
    "idx = ['entityCode', 'service', 'Dentro do Prazo LMin', 'Fora do Prazo LMin', 'Perto do Prazo LMin']\n",
    "df_sla_1 = df_sla_1.pivot(columns = 'StatusLmax', values = 'limiteMaximo', index=idx).reset_index()\n",
    "df_sla_1.columns.name = None\n",
    "dic_renome = {'Dentro do prazo' : 'Dentro do Prazo LMax', \n",
    "              'Fora do prazo' : 'Fora do Prazo LMax',\n",
    "              'Perto do prazo' : 'Perto do Prazo LMax'}\n",
    "df_sla_1.rename(columns=dic_renome, inplace = True)\n",
    "\n",
    "# agrupa por entidade e serviço\n",
    "df_sla_1 = df_sla_1.groupby('service').sum().reset_index()\n",
    "\n",
    "# df_sla_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset form</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.402287Z",
     "start_time": "2021-03-04T11:12:41.398794Z"
    }
   },
   "outputs": [],
   "source": [
    "df_form_1 = df_form.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.420732Z",
     "start_time": "2021-03-04T11:12:41.408636Z"
    }
   },
   "outputs": [],
   "source": [
    "# faz pivot da coluna atributo\n",
    "df_form_1 = df_form_1.pivot(columns='atributo', values='valor', index='protocolo').reset_index()\n",
    "df_form_1.columns.name = None\n",
    "\n",
    "# renomeia colunas\n",
    "dic_renome = {'protocolo': 'Solicitacao', \n",
    "              'zipcode': 'CEP', \n",
    "              'street': 'Endereco', \n",
    "              'neighborhood': 'Bairro', \n",
    "              'city': 'Cidade', \n",
    "              'state': 'UF'}\n",
    "df_form_1.rename(columns=dic_renome, inplace = True)\n",
    "\n",
    "# df_form_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.438046Z",
     "start_time": "2021-03-04T11:12:41.425739Z"
    }
   },
   "outputs": [],
   "source": [
    "# substitui a coluna Endereco por branco quando '-' ou null\n",
    "df_form_1.loc[(df_form_1['Endereco'] == '-') | (df_form_1['Endereco'].isnull()), ['Endereco']] = ''\n",
    "df_form_1.loc[(df_form_1['Bairro'] == '-') | (df_form_1['Bairro'].isnull()), ['Bairro']] = ''\n",
    "\n",
    "# cria a coluna Endereco Completo\n",
    "df_form_1['EnderecoCompleto'] = df_form_1['Cidade'] + ', ' + df_form_1['UF'] + ', Brasil'\n",
    "\n",
    "# df_form_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset rating</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.443401Z",
     "start_time": "2021-03-04T11:12:41.440304Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rating_1 = df_rating.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.457893Z",
     "start_time": "2021-03-04T11:12:41.445933Z"
    }
   },
   "outputs": [],
   "source": [
    "# renomeia as colunas\n",
    "cols = ['Solicitacao', 'NotaAvaliacao', 'MotivoAvaliacao', 'DataHoraAvaliacao']\n",
    "df_rating_1.columns = cols\n",
    "\n",
    "# separa e formata as colunas de datas e horas \n",
    "df_rating_1['DataAvaliacao'] = pd.to_datetime(df_rating_1['DataHoraAvaliacao']).dt.date\n",
    "df_rating_1['HoraAvaliacao'] = pd.to_datetime(df_rating_1['DataHoraAvaliacao']).dt.time\n",
    "\n",
    "# deleta a coluna que contém data e hora\n",
    "df_rating_1.drop(['DataHoraAvaliacao'], axis=1, inplace=True)\n",
    "\n",
    "# preenche colunas de linhas vazias\n",
    "df_rating_1.loc[df_rating_1['MotivoAvaliacao'] == '', 'MotivoAvaliacao'] = '<motivo vazio>'\n",
    "\n",
    "# df_rating_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>trata o dataset tasks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.493314Z",
     "start_time": "2021-03-04T11:12:41.460641Z"
    }
   },
   "outputs": [],
   "source": [
    "SEM_STATUS = '<sem status inicial>'\n",
    "\n",
    "# renomeia as colunas\n",
    "lst_colunas_tasks = ['Protocolo', 'Entidade', 'Servico', 'Usuarios','Grupo', 'DataHora_Conclusao',\n",
    "                      'DataHora_Criacao', 'Acao', 'EncaminhadoPara', 'ProcessoEncerrado', 'ProcessoCancelado',\n",
    "                      'MotivoCancelamento', 'StatusExterno', 'Categoria', 'GrupoResponsavel','Prazo']\n",
    "df_tasks.columns = lst_colunas_tasks\n",
    "# df_tasks.head()\n",
    "\n",
    "# copia o dataset tasks e já orderna para preencher os status externos que estão vazios\n",
    "df_T = df_tasks.copy().sort_values(['Entidade', 'Protocolo', 'DataHora_Criacao']).reset_index(drop=True)\n",
    "\n",
    "# rotina para preencher status externo vazio\n",
    "# pega sempre o anterior e se o primeiro status estiver vazio coloca \"sem status inicial\"\n",
    "if df_T.loc[0, 'StatusExterno'] == '':\n",
    "    df_T.loc[0, 'StatusExterno'] = SEM_STATUS\n",
    "for i in range(1, df_T.shape[0]):\n",
    "    if df_T.loc[i, 'StatusExterno'] == '':    \n",
    "        if df_T.loc[i, 'Protocolo'] == df_T.loc[i - 1, 'Protocolo']:\n",
    "            df_T.loc[i, 'StatusExterno'] = df_T.loc[i - 1, 'StatusExterno']\n",
    "        else:\n",
    "            df_T.loc[i, 'StatusExterno'] = SEM_STATUS\n",
    "# df_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.506446Z",
     "start_time": "2021-03-04T11:12:41.495960Z"
    }
   },
   "outputs": [],
   "source": [
    "if df_T.loc[0, 'StatusExterno'] == '':\n",
    "    df_T.loc[0, 'StatusExterno'] = '<sem status inicial>'\n",
    "for i in range(1, df_T.shape[0]):\n",
    "    if df_T.loc[i, 'StatusExterno'] == '':    \n",
    "        if df_T.loc[i, 'Protocolo'] == df_T.loc[i - 1, 'Protocolo']:\n",
    "            df_T.loc[i, 'StatusExterno'] = df_T.loc[i - 1, 'StatusExterno']\n",
    "        else:\n",
    "            df_T.loc[i, 'StatusExterno'] = '<sem status inicial>'\n",
    "# df_T[['Protocolo', 'StatusExterno']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>monta tabelas dimensões</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM acoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.523876Z",
     "start_time": "2021-03-04T11:12:41.509397Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Acao em uma coluna do tipo \"category'\n",
    "df_T['tmpAcao'] = df_T['Acao'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Ação\n",
    "df_T['FK_dim_Acoes'] = df_T['tmpAcao'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Acao = df_T.loc[:, ['FK_dim_Acoes', 'Acao']].drop_duplicates()\n",
    "df_dim_Acao.rename(columns={'FK_dim_Acao': 'PK_dim_Acao'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Acoes de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Acao', 'tmpAcao'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.531772Z",
     "start_time": "2021-03-04T11:12:41.526350Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Acao.loc[df_dim_Acao['Acao'] == '', ['Acao']] = '<sem ação determinada>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM categoria servicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.547718Z",
     "start_time": "2021-03-04T11:12:41.534729Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Categoria em uma coluna do tipo \"category'\n",
    "df_T['tmpCategoria'] = df_T['Categoria'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão CategoriasServicos\n",
    "df_T['FK_dim_CategoriasServicos'] = df_T['tmpCategoria'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Categoria = df_T.loc[:, ['FK_dim_CategoriasServicos', 'Categoria']].drop_duplicates()\n",
    "df_dim_Categoria.rename(columns={'FK_dim_CategoriasServicos': 'PK_dim_CategoriasServicos'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Categoria de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Categoria', 'tmpCategoria'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.555081Z",
     "start_time": "2021-03-04T11:12:41.549957Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Categoria.loc[df_dim_Categoria['Categoria'] == '', ['Categoria']] = '<categoria indefinida>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM encaminhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.570485Z",
     "start_time": "2021-03-04T11:12:41.557619Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna EncaminhadoPara em uma coluna do tipo \"category'\n",
    "df_T['tmpEncaminhadoPara'] = df_T['EncaminhadoPara'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Encaminhamento\n",
    "df_T['FK_dim_Encaminhamento'] = df_T['tmpEncaminhadoPara'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Encaminhamento = df_T.loc[:, ['FK_dim_Encaminhamento', 'EncaminhadoPara']].drop_duplicates()\n",
    "df_dim_Encaminhamento.rename(columns={'FK_dim_Encaminhamento': 'PK_dim_Encaminhamento'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Entidade de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['EncaminhadoPara', 'tmpEncaminhadoPara'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Encaminhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.579312Z",
     "start_time": "2021-03-04T11:12:41.573067Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Encaminhamento.loc[df_dim_Encaminhamento['EncaminhadoPara'] == '', ['EncaminhadoPara']] = '<sem encaminhamento>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM entidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.597636Z",
     "start_time": "2021-03-04T11:12:41.582748Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Entidade em uma coluna do tipo \"category'\n",
    "df_T['tmpEntidade'] = df_T['Entidade'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Entidades\n",
    "df_T['FK_dim_Entidades'] = df_T['tmpEntidade'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Entidade = df_T.loc[:, ['FK_dim_Entidades', 'Entidade']].drop_duplicates()\n",
    "df_dim_Entidade['Entidade'] = df_dim_Entidade['Entidade'].str.upper()\n",
    "df_dim_Entidade.rename(columns={'FK_dim_Entidades': 'PK_dim_Entidades'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Entidade de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Entidade', 'tmpEntidade'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Entidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:47:12.202687Z",
     "start_time": "2021-02-22T13:47:12.199639Z"
    }
   },
   "source": [
    "## DIM grupo responsavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.612749Z",
     "start_time": "2021-03-04T11:12:41.600555Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna GrupoResponsavel em uma coluna do tipo \"category'\n",
    "df_T['tmpGrupoResponsavel'] = df_T['GrupoResponsavel'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão GrupoResponsavel\n",
    "df_T['FK_dim_GrupoResponsavel'] = df_T['tmpGrupoResponsavel'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_GrupoResponsavel = df_T.loc[:, ['FK_dim_GrupoResponsavel', 'GrupoResponsavel']].drop_duplicates()\n",
    "df_dim_GrupoResponsavel.rename(columns={'FK_dim_GrupoResponsavel': 'PK_dim_GrupoResponsavel'}, inplace = True)\n",
    "\n",
    "# exclui a coluna GrupoResponsavel de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['GrupoResponsavel', 'tmpGrupoResponsavel'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_GrupoResponsavel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM grupo usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.629281Z",
     "start_time": "2021-03-04T11:12:41.615247Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Grupo em uma coluna do tipo \"category'\n",
    "df_T['tmpGrupo'] = df_T['Grupo'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Grupo\n",
    "df_T['FK_dim_GruposUsuarios'] = df_T['tmpGrupo'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Grupo = df_T.loc[:, ['FK_dim_GruposUsuarios', 'Grupo']].drop_duplicates()\n",
    "df_dim_Grupo.rename(columns={'FK_dim_GruposUsuarios': 'PK_dim_GruposUsuarios'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Grupo de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Grupo', 'tmpGrupo'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.637459Z",
     "start_time": "2021-03-04T11:12:41.631830Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Grupo.loc[df_dim_Grupo['Grupo'] == '', ['Grupo']] = '<grupo usuário não definido>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM motivos cancelamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.654024Z",
     "start_time": "2021-03-04T11:12:41.641164Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna MotivoCancelamento em uma coluna do tipo \"category'\n",
    "df_T['tmpMotivoCancelamento'] = df_T['MotivoCancelamento'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão MotivoCanc\n",
    "df_T['FK_dim_MotivosCanc'] = df_T['tmpMotivoCancelamento'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_MotivoCanc = df_T.loc[:, ['FK_dim_MotivosCanc', 'MotivoCancelamento']].drop_duplicates()\n",
    "df_dim_MotivoCanc.rename(columns={'FK_dim_MotivosCanc': 'PK_dim_MotivosCanc'}, inplace = True)\n",
    "\n",
    "# exclui a coluna MotivoCancelamento de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['MotivoCancelamento', 'tmpMotivoCancelamento'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_MotivoCanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.661618Z",
     "start_time": "2021-03-04T11:12:41.656491Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_MotivoCanc.loc[df_dim_MotivoCanc['MotivoCancelamento'] == '', ['MotivoCancelamento']] = '<sem motivo de cancelamento>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.684029Z",
     "start_time": "2021-03-04T11:12:41.671563Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Servico em uma coluna do tipo \"category'\n",
    "df_T['tmpServico'] = df_T['Servico'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Servico\n",
    "df_T['FK_dim_Servicos'] = df_T['tmpServico'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Servicos = df_T.loc[:, ['FK_dim_Servicos', 'Servico']].drop_duplicates()\n",
    "\n",
    "# exclui a coluna Servico de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Servico', 'tmpServico'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Servicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.698304Z",
     "start_time": "2021-03-04T11:12:41.688151Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = {'FK_dim_Servicos': 'PK_dim_Servicos',\n",
    "        'Dentro do Prazo LMin': 'sla_VD_Lmin',\n",
    "        'Perto do Prazo LMin': 'sla_AM_Lmin',\n",
    "        'Fora do Prazo LMin': 'sla_VM_Lmin',\n",
    "        'Dentro do Prazo LMax': 'sla_VD_Lmax',\n",
    "        'Perto do Prazo LMax': 'sla_AM_LMax',\n",
    "        'Fora do Prazo LMax': 'sla_VM_LMax',\n",
    "       }\n",
    "# faz um merge da dimensão dim_Servicos com a tabela de SLAs\n",
    "df_dim_Servicos = df_dim_Servicos.merge(df_sla_1, left_on='Servico', right_on='service', how='left')\n",
    "df_dim_Servicos = df_dim_Servicos.drop('service', axis=1)\n",
    "df_dim_Servicos.rename(columns=cols, inplace = True)\n",
    "\n",
    "# df_dim_Servicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM status externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.713024Z",
     "start_time": "2021-03-04T11:12:41.700779Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna StatusExterno em uma coluna do tipo \"category'\n",
    "df_T['tmpStatusExterno'] = df_T['StatusExterno'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Grupo\n",
    "df_T['FK_dim_StatusExt'] = df_T['tmpStatusExterno'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_StatusExt = df_T.loc[:, ['FK_dim_StatusExt', 'StatusExterno']].drop_duplicates()\n",
    "df_dim_StatusExt.rename(columns={'FK_dim_StatusExt': 'PK_dim_StatusExt'}, inplace = True)\n",
    "\n",
    "# exclui a coluna Grupo de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['StatusExterno', 'tmpStatusExterno'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_StatusExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.721144Z",
     "start_time": "2021-03-04T11:12:41.715649Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_StatusExt.loc[df_dim_StatusExt['StatusExterno'] == '', ['StatusExterno']] = '<sem status>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.737094Z",
     "start_time": "2021-03-04T11:12:41.723955Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnforma a coluna Usuario em uma coluna do tipo \"category'\n",
    "df_T['tmpUsuario'] = df_T['Usuarios'].astype('category')\n",
    "\n",
    "# cria uma nova coluna que será a coluna chave primária da dimensão Usuario\n",
    "df_T['FK_dim_Usuarios'] = df_T['tmpUsuario'].cat.codes.astype('int64') + 1\n",
    "\n",
    "# tira a duplicidade\n",
    "df_dim_Usuario = df_T.loc[:, ['FK_dim_Usuarios', 'Usuarios']].drop_duplicates()\n",
    "col_ren = {'FK_dim_Usuarios': 'PK_dim_Usuarios', 'Usuarios': 'Usuario'}\n",
    "df_dim_Usuario.rename(columns=col_ren, inplace = True)\n",
    "\n",
    "# exclui a coluna Usuario de df_tasks que será a futura tabela fato\n",
    "df_T.drop(['Usuarios', 'tmpUsuario'], axis=1, inplace=True)\n",
    "\n",
    "# df_dim_Usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.744600Z",
     "start_time": "2021-03-04T11:12:41.739361Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Usuario.loc[df_dim_Usuario['Usuario'] == '', ['Usuario']] = '<usuário indefinido>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM situacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.752240Z",
     "start_time": "2021-03-04T11:12:41.747384Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dim_Situacao = pd.DataFrame({'PK_dim_Situacao': [1, 2, 3],\n",
    "                                'Situacao':        ['em Andamento', 'Encerrada', 'Cancelada']}\n",
    "                    )\n",
    "# df_dim_Situacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.759858Z",
     "start_time": "2021-03-04T11:12:41.754920Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dim_SLA = pd.DataFrame({'PK_dim_SLA': [1, 2, 3],\n",
    "                           'DescSLA':    ['dentro do prazo', 'perto do prazo', 'fora do prazo'],\n",
    "                           'Cor':        ['verde','amarelo' ,'vermelho']}\n",
    "                    )\n",
    "# df_dim_SLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIM endereco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.771783Z",
     "start_time": "2021-03-04T11:12:41.762946Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_uf = {'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas', 'BA': 'Bahia',\n",
    "           'CE': 'Ceará', 'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão', 'MT': 'Mato Grosso',\n",
    "           'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "           'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí', 'RJ': 'Rio de Janeiro',\n",
    "           'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul', 'RO': 'Rondônia', 'RR': 'Roraima',\n",
    "           'SC': 'Santa Catarina', 'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins', 'DF': 'Distrito Federal',\n",
    "           '<nd>': '<sem UF>'\n",
    "}\n",
    "\n",
    "# acrescenta o nome do estado ao dataframe\n",
    "df_dim_Endereco = df_form_1.copy()\n",
    "df_dim_Endereco['NomeUF'] = df_dim_Endereco['UF'].apply(lambda x: dict_uf.get(x, None))\n",
    "df_dim_Endereco.rename(columns={'Solicitacao': 'PK_dim_Endereco'}, inplace = True)\n",
    "\n",
    "# df_dim_Endereco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.778461Z",
     "start_time": "2021-03-04T11:12:41.774193Z"
    }
   },
   "outputs": [],
   "source": [
    "# preenche colunas com linhas vazias\n",
    "df_dim_Endereco.loc[df_dim_Endereco['CEP'].isna(), ['CEP']] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAT tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.788964Z",
     "start_time": "2021-03-04T11:12:41.781083Z"
    }
   },
   "outputs": [],
   "source": [
    "df_T2 = df_T.copy().sort_values(['FK_dim_Entidades', 'Protocolo', 'DataHora_Criacao']).reset_index(drop=True)\n",
    "\n",
    "# df_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.794561Z",
     "start_time": "2021-03-04T11:12:41.791084Z"
    }
   },
   "outputs": [],
   "source": [
    "# função retorna a situação da solicitação de acordo com as coilunas cancelado e encerrado\n",
    "def RetSit(Enc, Canc):\n",
    "    rt = 0\n",
    "    if Canc == 1:\n",
    "        rt = 3\n",
    "    elif Enc == 1:\n",
    "        rt = 2\n",
    "    else:\n",
    "        rt = 1\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.838026Z",
     "start_time": "2021-03-04T11:12:41.796815Z"
    }
   },
   "outputs": [],
   "source": [
    "# faz um merge com o dataset de ratings\n",
    "df_T2 = df_T2.merge(df_rating_1, left_on='Protocolo', right_on='Solicitacao', how='left')\n",
    "df_T2.drop(['Solicitacao'], axis=1, inplace=True)\n",
    "\n",
    "# define o código de situação da solicitação\n",
    "df_aux = df_T2[['Protocolo', 'ProcessoEncerrado', 'ProcessoCancelado']].drop_duplicates()\n",
    "\n",
    "# substui valores de colunas\n",
    "troca = {'false': 0, 'true': 1}\n",
    "df_aux['ProcessoEncerrado'] = df_aux['ProcessoEncerrado'].map(troca)\n",
    "df_aux['ProcessoCancelado'] = df_aux['ProcessoCancelado'].map(troca)\n",
    "\n",
    "# agrega as ações para um registro por protocolo\n",
    "df_aux = df_aux.groupby('Protocolo').agg({'ProcessoEncerrado': 'max', 'ProcessoCancelado': 'max'}).reset_index()\n",
    "\n",
    "# retorna a situção da solicitação: 1-em andamento, 2-encerrado, 3-cancelado\n",
    "df_aux['Situacao'] = df_aux.apply(lambda x: RetSit(x['ProcessoEncerrado'], x['ProcessoCancelado']), axis=1)\n",
    "df_aux.drop(['ProcessoEncerrado', 'ProcessoCancelado'], axis=1, inplace=True)\n",
    "\n",
    "# faz merge com o dataset de situação da solicitação\n",
    "df_T2 = df_T2.merge(df_aux, left_on='Protocolo', right_on='Protocolo', how='left')\n",
    "df_T2.drop(['ProcessoEncerrado', 'ProcessoCancelado'], axis=1, inplace=True)\n",
    "\n",
    "# coloca -1 para as solicitações que não possuem avaliação\n",
    "df_T2.loc[df_T2['NotaAvaliacao'].isna(), 'NotaAvaliacao'] = -1\n",
    "df_T2['NotaAvaliacao'] = df_T2['NotaAvaliacao'].astype('int32')\n",
    "\n",
    "# renomeia as colunas\n",
    "col_ren = {'Protocolo': 'FK_dim_Solicitacoes', 'Situacao': 'FK_dim_Situacao'}\n",
    "df_T2.rename(columns=col_ren, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.847779Z",
     "start_time": "2021-03-04T11:12:41.840280Z"
    }
   },
   "outputs": [],
   "source": [
    "# trata a coluna Prazo\n",
    "df_T2['Prazo'] == ''\n",
    "df_T2.loc[df_T2['Prazo'] == '', 'Prazo'] = '0'\n",
    "df_T2['Prazo'] = df_T2['Prazo'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.867035Z",
     "start_time": "2021-03-04T11:12:41.849616Z"
    }
   },
   "outputs": [],
   "source": [
    "df_T2['DataCriacao'] = pd.to_datetime(df_T2['DataHora_Criacao']).dt.date\n",
    "df_T2['HoraCriacao'] = pd.to_datetime(df_T2['DataHora_Criacao']).dt.time\n",
    "\n",
    "df_T2['DataConclusao'] = pd.to_datetime(df_T2['DataHora_Conclusao']).dt.date\n",
    "df_T2['HoraConclusao'] = pd.to_datetime(df_T2['DataHora_Conclusao']).dt.time\n",
    "\n",
    "df_T2.drop(['DataHora_Criacao', 'DataHora_Conclusao'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.874425Z",
     "start_time": "2021-03-04T11:12:41.869261Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_ordem = ['FK_dim_Solicitacoes', 'Prazo', 'DataCriacao', 'HoraCriacao', \n",
    "              'DataConclusao', 'HoraConclusao', \n",
    "              'NotaAvaliacao', 'MotivoAvaliacao', \n",
    "              'DataAvaliacao', 'HoraAvaliacao', \n",
    "              'FK_dim_Entidades', 'FK_dim_Servicos', 'FK_dim_Usuarios', 'FK_dim_GruposUsuarios', \n",
    "              'FK_dim_Acoes', 'FK_dim_StatusExt', 'FK_dim_CategoriasServicos', 'FK_dim_GrupoResponsavel', \n",
    "              'FK_dim_MotivosCanc', 'FK_dim_Encaminhamento', 'FK_dim_Situacao'\n",
    "            ]\n",
    "df_T2 = df_T2[cols_ordem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:41.879542Z",
     "start_time": "2021-03-04T11:12:41.876611Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_T2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>3.0 LOAD</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grava tabelas DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:42.066893Z",
     "start_time": "2021-03-04T11:12:41.882303Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the module\n",
    "# create sqlalchemy engine\n",
    "My_host = 'localhost'; My_db = 'bd_teste_dw'; My_user = 'gd'; My_pw = 'Alpar@123'\n",
    "\n",
    "SQLengine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user = AUTENTIC_OUT['My_user'], \n",
    "                               pw =   AUTENTIC_OUT['My_pw'], \n",
    "                               db =   AUTENTIC_OUT['My_db']), \n",
    "                               pool_recycle=3600)\n",
    "dbConn = SQLengine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T11:12:42.612967Z",
     "start_time": "2021-03-04T11:12:42.072237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas criadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_dim_Acao.to_sql('dim_acoes', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Categoria.to_sql('dim_categorias_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Encaminhamento.to_sql('dim_encaminhamento', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Entidade.to_sql('dim_entidades', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_GrupoResponsavel.to_sql('dim_grupo_responsavel', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Grupo.to_sql('dim_grupos_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_MotivoCanc.to_sql('dim_motivos_canc', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Servicos.to_sql('dim_servicos', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_StatusExt.to_sql('dim_status_ext', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Usuario.to_sql('dim_usuarios', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Situacao.to_sql('dim_situacao', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_SLA.to_sql('dim_sla', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "    df_dim_Endereco.to_sql('dim_endereco', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "    df_T2.to_sql('fat_tasks', con=dbConn, if_exists='replace', index=False, chunksize = 1000)\n",
    "\n",
    "except ValueError as vx:\n",
    "    print('ERROR -', vx)\n",
    "\n",
    "except Exception as ex:\n",
    "    print('EXCEPTION -', ex)\n",
    "\n",
    "else:\n",
    "    print('Tabelas criadas com sucesso');  \n",
    "\n",
    "finally:\n",
    "    dbConn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
